{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsHSQ1TEXDNZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "from simulation_util import client_update\n",
    "import warnings\n",
    "\n",
    "# hide the warning message temporarily\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# auto-reload the modules everytime a cell is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfZrf09ZofuP"
   },
   "source": [
    "## Client Update Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "fZj9flYHXNd4",
    "outputId": "09beecb0-cd45-46d6-9932-77cef46d5044",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[28.48292602, -0.02900163, -0.04329029]]), array([-9.00973908])]\n"
     ]
    }
   ],
   "source": [
    "# this data will be provided by the server\n",
    "features = [[1, 4, 3], [0, 2, 2], [1, 4, 0], [0, 5, 3], [1, 2, 1], [0, 2, 9]]\n",
    "labels = [1, 0, 1, 0, 1, 0]\n",
    "\n",
    "coefs = np.array([29., 0., 0.]) # should be of size num_classes * num_features\n",
    "intercepts = np.array([-9])\n",
    "weights = [coefs, intercepts]\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 3\n",
    "\n",
    "new_weights = client_update(weights, epochs, batch_size, features, labels)\n",
    "print(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Update Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weights:  [[ 4.75450975 -2.44971341  4.40047858]] [-9.20703972]\n",
      "Updated Weights:  [[  6.71901712 -10.38477388   3.39131083]] [5.5717736]\n",
      "Updated Weights:  [[ 6.95792936 -7.29211908  6.28516806]] [-8.25096537]\n",
      "Updated Weights:  [[3.51996821 7.01965866 5.21825586]] [7.89624394]\n",
      "Updated Weights:  [[-8.30318559  6.09994066 -4.22280758]] [-7.68441356]\n",
      "Updated Weights:  [[ 3.90333898  0.70948686 -1.87217782]] [13.40375092]\n",
      "Updated Weights:  [[-11.7494913    3.47976377   4.0840828 ]] [-16.32461824]\n",
      "Updated Weights:  [[-3.9286137  -2.47186698  6.09179214]] [5.84250549]\n",
      "Updated Weights:  [[-4.21205324 -2.11821868  6.23597035]] [-3.37561152]\n",
      "Updated Weights:  [[-5.16678509 10.0400736  -2.46470228]] [-3.46428207]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from simulation_util import server_update\n",
    "\n",
    "init_weights = [np.array([0, 0, 0]), np.array([0])]\n",
    "client_fraction = 0.5\n",
    "num_rounds = 10\n",
    "epoch = 10\n",
    "batch_size = 25\n",
    "display_weight_per_round = True\n",
    "\n",
    "num_client = 100\n",
    "samples_per_client = 100\n",
    "num_features = 3\n",
    "features = np.random.randint(10, size=(num_client, samples_per_client, num_features))\n",
    "labels = np.random.randint(2, size=(num_client, samples_per_client))\n",
    "\n",
    "new_clf = server_update(init_weights, client_fraction, num_rounds, features, labels, epoch, batch_size, display_weight_per_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Simulation Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000, 1)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [7 7 7 ... 8 8 8]\n",
      " [8 8 8 ... 9 9 9]\n",
      " [9 9 9 ... 9 9 9]]\n",
      "(100, 700)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'user_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-c353d2fef285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0msim_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdata_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_data_for_simulator_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_prms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/CANOSP-2019/random_data_gen.py\u001b[0m in \u001b[0;36mtransform_data_for_simulator_format\u001b[0;34m(df, g_prms)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_prms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mclient_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         client_feats = client_df.drop(columns=[\"user_id\", \"labels\"]).to_records(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'user_id'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "from simulation_util import server_update\n",
    "import numpy as np\n",
    "import random_data_gen as rdata_gen\n",
    "import pandas as pd\n",
    "from numpy import zeros, newaxis\n",
    "\n",
    "# Load the data\n",
    "NUM_SAMPLES = 70000\n",
    "NUM_LABELS = 10\n",
    "NUM_FEATURES = 784\n",
    "NUM_CLIENTS = 100\n",
    "g_prms = rdata_gen.InputGenParams(NUM_SAMPLES, NUM_LABELS, NUM_FEATURES, NUM_CLIENTS)\n",
    "df = pd.read_csv(\"datasets/test.csv\",header=None)\n",
    "# df.drop(dp.columns[-1],axis=1)\n",
    "data = df.to_numpy()\n",
    "features = data[:,range(data.shape[1]-1)]\n",
    "labels = data[:,[data.shape[1]-1]]\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "reshaped_feature = []\n",
    "reshaped_label = []\n",
    "# features = features[:, :, newaxis]\n",
    "# labels = labels[:,:,newaxis]\n",
    "\n",
    "for i in range(0,len(features),NUM_SAMPLES//NUM_CLIENTS):\n",
    "    reshaped_feature.append(features[i:i+NUM_SAMPLES//NUM_CLIENTS])\n",
    "#     print(labels[i:i+NUM_SAMPLES//NUM_CLIENTS].flatten())\n",
    "    reshaped_label.append(labels[i:i+NUM_SAMPLES//NUM_CLIENTS].flatten())\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "reshaped_feature = np.array(reshaped_feature)    \n",
    "reshaped_label = np.array(reshaped_label) \n",
    "print(reshaped_label)\n",
    "print(reshaped_label.shape)\n",
    "\n",
    "\n",
    "# features.reshape(NUM_CLIENTS,NUM_FEATURES,NUM_SAMPLES)\n",
    "# labels.reshape(NUM_CLIENTS,NUM_FEATURES,NUM_SAMPLES)\n",
    "\n",
    "\n",
    "sim_labels, sim_features = rdata_gen.transform_data_for_simulator_format(df, g_prms)\n",
    "features = np.array(sim_features)\n",
    "labels = np.array(sim_labels)\n",
    "\n",
    "\n",
    "# (100, 200, 4)\n",
    "# (100, 200)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=0)\n",
    "\n",
    "print(X_train[0][0])\n",
    "print(y_train[0][0])\n",
    "\n",
    "# (60, 200, 4)\n",
    "# (60, 200)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "init_weights = np.zeros((NUM_LABELS, NUM_FEATURES), dtype=np.float64, order=\"C\")\n",
    "# init_weights = np.array([[ 4.99547008,  5.62897696,  9.68194524, -6.54602355],\n",
    "#        [ 6.49729334,  8.97500002,  9.1586204 , -2.78742303],\n",
    "#        [-4.23699246, 10.53697248,  7.5595605 , -6.49384498]])\n",
    "init_intercept = np.zeros(NUM_LABELS, dtype=np.float64, order=\"C\")\n",
    "# init_intercept = np.array([-136.32219189, -138.92717176, -136.08247396])\n",
    "\n",
    "# Find all the permutations of the parameters\n",
    "param_grid = {\"client_fraction\": [1],\n",
    "              \"epoch\": [30, 40],\n",
    "              \"batch_size\": [40, 80], # TODO: need to implement an infinite batch size\n",
    "              \"init_weight\": [[init_weights, init_intercept]],\n",
    "              \"num_rounds\": [10]}\n",
    "\n",
    "# run training/testing over all parameter combinations to get the best combination\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(\"Training...\")\n",
    "    print(\"Params: \", params)\n",
    "    classifier = server_update(params[\"init_weight\"], params[\"client_fraction\"], params[\"num_rounds\"], X_train, y_train, params[\"epoch\"], params[\"batch_size\"], False)\n",
    "    weights = [classifier.coef_, classifier.intercept_]\n",
    "\n",
    "    # need to remove the client dimension from our data for testing \n",
    "    # ex: [[[1, 1], [2, 2]], [[3, 3], [4, 4]]] needs to become [[1, 1], [2, 2], [3, 3], [4, 4]] for features \n",
    "    # and [[1, 2], [3, 4]] needs to become [1, 2, 3, 4] for labels \n",
    "    reshaped_X_test = np.reshape(X_test, (X_test.shape[0] * X_test.shape[1], X_test.shape[2]))\n",
    "    reshaped_y_test = np.reshape(y_test, y_test.size)\n",
    "    \n",
    "    score = classifier.score(reshaped_X_test, reshaped_y_test)\n",
    "\n",
    "    print('Weights: {}\\nScore: {:f}\\n\\n'.format(weights, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Federated Learning Simulation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
